{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c8b1abd-794e-4545-ad21-24bfd24bd8fa",
   "metadata": {},
   "source": [
    "# This code contains all the process of extraction and processing of the images from the ACDC Dataset, and the calculation of the topological descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "806e40e3-e260-422e-b8bc-1d49a5af10a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import nibabel as nib\n",
    "from gudhi import CubicalComplex\n",
    "from gudhi.wasserstein import wasserstein_distance\n",
    "from gudhi.representations import Entropy\n",
    "import itertools\n",
    "from itertools import groupby\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17498c74-dadd-462e-b6d7-94434edd16d4",
   "metadata": {},
   "source": [
    "## For this code to work properly, the ACDC Dataset should be downloaded without changes from https://humanheart-project.creatis.insa-lyon.fr/database/#collection/637218c173e9f0047faa00fb and there should be an nnunet folder with the model used for segmentation (see nnUNet_README). We provide trial data (just one patient and its nnUNET segmentation masks) that allows testing of this notebook. The next flag controls the use of either option (False means default use, True means Trial use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1317c54b-0420-43cd-bd14-c5313769c119",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_flag=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac95bc2-ffc6-4b8d-ae9d-bcf94bed2e2d",
   "metadata": {},
   "source": [
    "### Information about the patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "590f4000-7a65-477b-9940-13b2c5ca4787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the end-diastole and end-systole frame number for each patient.\n",
    "if trial_flag:\n",
    "    base_path=\"Trial/patient/\"\n",
    "    range_database=2\n",
    "else:\n",
    "    base_path=\"ACDC/ACDC/database/\"\n",
    "    range_database=151\n",
    "\n",
    "duplets = []\n",
    "\n",
    "# This loop is used to extract the data from the ACDC Dataset directly\n",
    "for i in range(1,range_database):\n",
    "    patient_path=\"patient\"\n",
    "    if (i <= 100):\n",
    "        info_path=base_path+\"training/\"\n",
    "        if (i < 100):\n",
    "            patient_path=patient_path+\"0\"\n",
    "            if (i < 10):\n",
    "                patient_path=patient_path+\"0\"\n",
    "    else:\n",
    "        info_path=base_path+\"testing/\"\n",
    "    \n",
    "    filepath=info_path+patient_path+str(i)+\"/\"+\"Info.cfg\"\n",
    "\n",
    "    with open(filepath, \"r\") as file:\n",
    "        ed_value = None\n",
    "        es_value = None\n",
    "            \n",
    "        for line in file:\n",
    "            if line.startswith(\"ED:\"):\n",
    "                ed_value = int(line.split(\":\")[1].strip())\n",
    "            if line.startswith(\"ES:\"):\n",
    "                es_value = int(line.split(\":\")[1].strip())\n",
    "            \n",
    "        if ed_value is not None and es_value is not None:\n",
    "            duplets.append((ed_value, es_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da3fa36-5439-4043-8cff-a5b37c65acb0",
   "metadata": {},
   "source": [
    "### Extraction of 3D Images and ROUSEG segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1549250c-1d2a-429c-92c9-af0841f9134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization between 0 and 1\n",
    "def normalize (image):\n",
    "    min_value = np.min(image)  \n",
    "    max_value = np.max(image) \n",
    "        \n",
    "    image = (image - min_value) / (max_value - min_value)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ee17a60-9014-4a64-b1e3-f64d81c02847",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This next cell does:\n",
    "#1. Save the 3D frames that are in the ED-ES range for each patient's video, so that we can generate masks with the nnUNet model\n",
    "#2. Apply the ROUSEG mask, normalize the three images and save them to calculate their persistence diagrams\n",
    "\n",
    "saved_images_dir=\"3DImagesPreFilter\"\n",
    "if not os.path.exists(saved_images_dir):\n",
    "    os.mkdir(saved_images_dir)\n",
    "rouseg_filtered_dir=\"ROUSEG\"\n",
    "if not os.path.exists(rouseg_filtered_dir):\n",
    "    os.mkdir(rouseg_filtered_dir)\n",
    "\n",
    "for i in range(1,range_database):\n",
    "    patient_path=\"patient\"\n",
    "    if (i <= 100):\n",
    "        image_path=base_path+\"training/\"\n",
    "        if (i < 100):\n",
    "            patient_path=patient_path+\"0\"\n",
    "            if (i < 10):\n",
    "                patient_path=patient_path+\"0\"\n",
    "    else:\n",
    "        image_path=base_path+\"testing/\"\n",
    "        \n",
    "    file_path=image_path+patient_path+str(i)+\"/\"+patient_path+str(i)+\"_4d.nii.gz\" #Video\n",
    "\n",
    "    #Take the ROUSEG Filter, which is the end-systole mask\n",
    "    if duplets[i-1][1]<10:\n",
    "        filter_path=image_path+patient_path+str(i)+\"/\"+patient_path+str(i)+\"_frame0\"+str(duplets[i-1][1])+\"_gt.nii.gz\"\n",
    "    else:\n",
    "        filter_path=image_path+patient_path+str(i)+\"/\"+patient_path+str(i)+\"_frame\"+str(duplets[i-1][1])+\"_gt.nii.gz\"\n",
    "\n",
    "    img = nib.load(file_path)\n",
    "    img_data = img.get_fdata()\n",
    "    \n",
    "    filter_img = nib.load(filter_path)\n",
    "    filter_img = filter_img.get_fdata()\n",
    "\n",
    "    rouseg_filtered_dir_R=rouseg_filtered_dir+\"/Right\"\n",
    "    if not os.path.exists(rouseg_filtered_dir_R):\n",
    "        os.mkdir(rouseg_filtered_dir_R)\n",
    "\n",
    "    rouseg_filtered_dir_M=rouseg_filtered_dir+\"/Myoca\"\n",
    "    if not os.path.exists(rouseg_filtered_dir_M):\n",
    "        os.mkdir(rouseg_filtered_dir_M)\n",
    "\n",
    "    rouseg_filtered_dir_L=rouseg_filtered_dir+\"/Left\"\n",
    "    if not os.path.exists(rouseg_filtered_dir_L):\n",
    "        os.mkdir(rouseg_filtered_dir_L)\n",
    "\n",
    "    for t in range(duplets[i-1][0],duplets[i-1][1]+1):\n",
    "        # Take the 3D slice corresponding to time t-1\n",
    "        img_3d_data = img_data[:, :, :, t-1]\n",
    "        img_3d = nib.Nifti1Image(img_3d_data, img.affine, img.header)\n",
    "\n",
    "        # The saving format is the concatenation of the three-digit number of the patient and the two-digit number of the frame\n",
    "        # The _0000 at the end is a condition for the nnUNet model and it makes no difference for us.\n",
    "        output_file_path = os.path.join(saved_images_dir, (patient_path+str(i))[-3:]+f'{t:02d}_0000.nii.gz')\n",
    "        nib.save(img_3d, output_file_path)\n",
    "\n",
    "        unique_values = np.unique(filter_img)\n",
    "        unique_values=unique_values[1:]\n",
    "        filtered_images=[]\n",
    "        for value in unique_values:\n",
    "            mask = (filter_img == value)\n",
    "            temp_image = img_3d_data * mask\n",
    "            temp_image = normalize(temp_image)\n",
    "            temp_image = nib.Nifti1Image(temp_image, img.affine, img.header)\n",
    "            filtered_images.append(temp_image)\n",
    "\n",
    "        #Save separated in Right, Myo i Left\n",
    "        output_file_path = os.path.join(rouseg_filtered_dir_R, (patient_path+str(i))[-3:]+f'{t:02d}.nii.gz')\n",
    "        nib.save(filtered_images[0], output_file_path)\n",
    "        output_file_path = os.path.join(rouseg_filtered_dir_M, (patient_path+str(i))[-3:]+f'{t:02d}.nii.gz')\n",
    "        nib.save(filtered_images[1], output_file_path)\n",
    "        output_file_path = os.path.join(rouseg_filtered_dir_L, (patient_path+str(i))[-3:]+f'{t:02d}.nii.gz')\n",
    "        nib.save(filtered_images[2], output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb49016a-92b0-4386-a100-ebc7ecdc4eee",
   "metadata": {},
   "source": [
    "### NETSEG Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4e0c26d-9bff-44ba-97b3-07a2bdde400d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter the images with the nnUNet masks. We did not write any code for the generation of the nnUNet masks; it is performed directly on the console.\n",
    "images_dir=\"3DImagesPreFilter/\"\n",
    "netseg_filtered_dir=\"NETSEG\"\n",
    "if not os.path.exists(netseg_filtered_dir):\n",
    "    os.mkdir(netseg_filtered_dir)\n",
    "\n",
    "if trial_flag:\n",
    "    netseg_filters_dir=\"Trial/nnunet_masks/\"\n",
    "else:\n",
    "    netseg_filters_dir=\"nnunet/output/\"\n",
    "\n",
    "\n",
    "#Only take the .nii.gz files\n",
    "images_files = sorted([f for f in os.listdir(images_dir) if f.endswith(\".nii.gz\")])\n",
    "filters_files = sorted([f for f in os.listdir(netseg_filters_dir) if f.endswith(\".nii.gz\")])\n",
    "\n",
    "#There should be exactly the same amount of images as filters\n",
    "if len(images_files) != len(filters_files):\n",
    "    raise ValueError(\"The number of .nii.gz files in the images and filters directories do not match.\")\n",
    "\n",
    "#Here we run through the image and filter directories simultaneously\n",
    "for image_file, filter_file in zip(images_files, filters_files):\n",
    "    image_path = os.path.join(images_dir, image_file)\n",
    "    filter_path = os.path.join(netseg_filters_dir, filter_file)\n",
    "\n",
    "    img = nib.load(image_path)\n",
    "    img_data = img.get_fdata()\n",
    "\n",
    "    filter_img = nib.load(filter_path)\n",
    "    filter_img_data = filter_img.get_fdata()\n",
    "\n",
    "    netseg_filtered_dir_R=netseg_filtered_dir+\"/Right\"\n",
    "    if not os.path.exists(netseg_filtered_dir_R):\n",
    "        os.mkdir(netseg_filtered_dir_R)\n",
    "\n",
    "    netseg_filtered_dir_M=netseg_filtered_dir+\"/Myoca\"\n",
    "    if not os.path.exists(netseg_filtered_dir_M):\n",
    "        os.mkdir(netseg_filtered_dir_M)\n",
    "\n",
    "    netseg_filtered_dir_L=netseg_filtered_dir+\"/Left\"\n",
    "    if not os.path.exists(netseg_filtered_dir_L):\n",
    "        os.mkdir(netseg_filtered_dir_L)\n",
    "\n",
    "    # Take the different regions of the heart\n",
    "    unique_values = np.unique(filter_img_data)\n",
    "    unique_values=unique_values[1:] #Ignore the first value (background)\n",
    "    filtered_images=[]\n",
    "    for value in unique_values:\n",
    "        mask = (filter_img_data == value)\n",
    "        temp_image = img_data * mask\n",
    "        temp_image = normalize(temp_image)\n",
    "        temp_image = nib.Nifti1Image(temp_image, img.affine, img.header)\n",
    "        filtered_images.append(temp_image)\n",
    "\n",
    "    #Save the filtered images. The order is different than for ROUSEG because the nnUNet masks have different colors\n",
    "    output_file_path = os.path.join(netseg_filtered_dir_L, filter_file)\n",
    "    nib.save(filtered_images[0], output_file_path)\n",
    "    output_file_path = os.path.join(netseg_filtered_dir_M, filter_file)\n",
    "    nib.save(filtered_images[1], output_file_path)\n",
    "    output_file_path = os.path.join(netseg_filtered_dir_R, filter_file)\n",
    "    nib.save(filtered_images[2], output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6226f52c-bd9d-4629-a8fe-28e6e69d7550",
   "metadata": {},
   "source": [
    "### Calculation and saving of topological descriptor lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dde0027c-6ee1-4780-9e16-dce8dbd74e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The images start with the number of the patient: 001, 002,..., 150\n",
    "def get_prefix(filename):\n",
    "    return filename[:3]\n",
    "\n",
    "#Function to extract the entropies and distance between diagrams.\n",
    "def calculate_entropies_and_distance (directory): \n",
    "\n",
    "    dlist=[]\n",
    "    e0list=[]\n",
    "    e1list=[]\n",
    "    e2list=[]\n",
    "\n",
    "    files = sorted([f for f in os.listdir(directory) if f.endswith(\".nii.gz\")])\n",
    "    \n",
    "    for prefix, group in groupby(files, key=get_prefix):\n",
    "\n",
    "        print(prefix)\n",
    "        grouped_files = list(group)\n",
    "        \n",
    "        patient_distance_list=[]\n",
    "        patient_e0_list=[]\n",
    "        patient_e1_list=[]\n",
    "        patient_e2_list=[]\n",
    "\n",
    "        # We need to take both the current frame and the next one, to compute the distacnes\n",
    "        for i, image_file in enumerate(grouped_files[:-1]):\n",
    "            path1 = os.path.join(directory, image_file)\n",
    "            path2 = os.path.join(directory, grouped_files[i+1])\n",
    "\n",
    "        # In the first frame, we compute its diagram and the entropies\n",
    "            if (image_file==grouped_files[0]):\n",
    "    \n",
    "                img_1 = nib.load(path1)\n",
    "                img_data_1 = img_1.get_fdata()\n",
    "        \n",
    "                cubical_complex = CubicalComplex(top_dimensional_cells=img_data_1)\n",
    "                cubical_complex.persistence()\n",
    "                entropy = Entropy()\n",
    "                \n",
    "                diagram1_h0 = cubical_complex.persistence_intervals_in_dimension(0)\n",
    "                if np.isinf(diagram1_h0[-1, 1]): #The infinite point is not taken into account in the calculation of entropy and distance so we remove it\n",
    "                    diagram1_h0 = diagram1_h0[:-1]\n",
    "                diagram1_h1 = cubical_complex.persistence_intervals_in_dimension(1)\n",
    "                diagram1_h2 = cubical_complex.persistence_intervals_in_dimension(2)\n",
    "        \n",
    "                h0_entropy = entropy.fit_transform([diagram1_h0])[0][0]\n",
    "                patient_e0_list.append(h0_entropy)\n",
    "                \n",
    "                h1_entropy = entropy.fit_transform([diagram1_h1])[0][0]\n",
    "                patient_e1_list.append(h1_entropy)\n",
    "\n",
    "                h2_entropy = entropy.fit_transform([diagram1_h2])[0][0]\n",
    "                patient_e2_list.append(h2_entropy)\n",
    "\n",
    "            # In the following frames, we have already calculated that diagram so no need to do it again\n",
    "            else:\n",
    "    \n",
    "                diagram1_h0=diagram2_h0\n",
    "                diagram1_h1=diagram2_h1\n",
    "                diagram1_h2=diagram2_h2\n",
    "\n",
    "            # In both cases, we compute the diagram corresponding to the next frame and compute the distance\n",
    "            img_2 = nib.load(path2)\n",
    "            img_data_2 = img_2.get_fdata()\n",
    "    \n",
    "            cubical_complex = CubicalComplex(top_dimensional_cells=img_data_2)\n",
    "            cubical_complex.persistence()\n",
    "            entropy = Entropy()\n",
    "            \n",
    "            diagram2_h0 = cubical_complex.persistence_intervals_in_dimension(0)\n",
    "            if np.isinf(diagram2_h0[-1, 1]):\n",
    "                    diagram2_h0 = diagram2_h0[:-1]\n",
    "            diagram2_h1 = cubical_complex.persistence_intervals_in_dimension(1)\n",
    "            diagram2_h2 = cubical_complex.persistence_intervals_in_dimension(2)\n",
    "    \n",
    "            h0_entropy = entropy.fit_transform([diagram2_h0])[0][0]\n",
    "            patient_e0_list.append(h0_entropy)\n",
    "            \n",
    "            h1_entropy = entropy.fit_transform([diagram2_h1])[0][0]\n",
    "            patient_e1_list.append(h1_entropy)\n",
    "\n",
    "            h2_entropy = entropy.fit_transform([diagram2_h2])[0][0]\n",
    "            patient_e2_list.append(h2_entropy)\n",
    "    \n",
    "            distance_h0 = wasserstein_distance(diagram1_h0, diagram2_h0, order=2)\n",
    "            distance_h1 = wasserstein_distance(diagram1_h1, diagram2_h1, order=2)\n",
    "            distance_h2 = wasserstein_distance(diagram1_h2, diagram2_h2, order=2)\n",
    "    \n",
    "            distance=distance_h0+distance_h1+distance_h2\n",
    "    \n",
    "            patient_distance_list.append(distance)\n",
    "    \n",
    "        dlist.append(patient_distance_list)\n",
    "        e0list.append(patient_e0_list)\n",
    "        e1list.append(patient_e1_list)\n",
    "        e2list.append(patient_e2_list)\n",
    "\n",
    "    return dlist, e0list, e1list, e2list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33eeb7f2-14c9-432a-9b85-954d86a63843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save the generated entropy and distances\n",
    "lists_dir=\"Lists/\"\n",
    "if not os.path.exists(lists_dir):\n",
    "    os.mkdir(lists_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2db749c7-45e1-459b-927b-c8df80ee3c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_list(listt, list_name, directory):\n",
    "    with open(directory+list_name,\"w\") as f:\n",
    "        json.dump(listt, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72f7f2d9-0643-460e-8b64-92342ed7ecc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001\n",
      "001\n",
      "001\n",
      "001\n",
      "001\n",
      "001\n"
     ]
    }
   ],
   "source": [
    "R_dist_ROUSEG, R_e0_ROUSEG, R_e1_ROUSEG, R_e2_ROUSEG = calculate_entropies_and_distance (\"ROUSEG/Right\")\n",
    "M_dist_ROUSEG, M_e0_ROUSEG, M_e1_ROUSEG, M_e2_ROUSEG = calculate_entropies_and_distance (\"ROUSEG/Myoca\")\n",
    "L_dist_ROUSEG, L_e0_ROUSEG, L_e1_ROUSEG, L_e2_ROUSEG = calculate_entropies_and_distance (\"ROUSEG/Left\")\n",
    "R_dist_NETSEG, R_e0_NETSEG, R_e1_NETSEG, R_e2_NETSEG = calculate_entropies_and_distance (\"NETSEG/Right\")\n",
    "M_dist_NETSEG, M_e0_NETSEG, M_e1_NETSEG, M_e2_NETSEG = calculate_entropies_and_distance (\"NETSEG/Myoca\")\n",
    "L_dist_NETSEG, L_e0_NETSEG, L_e1_NETSEG, L_e2_NETSEG = calculate_entropies_and_distance (\"NETSEG/Left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd255e2c-091f-465a-b92e-5643387a9303",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_list(R_dist_ROUSEG, \"R_dist_ROUSEG.json\", lists_dir)\n",
    "save_list(R_e0_ROUSEG, \"R_e0_ROUSEG.json\",lists_dir)\n",
    "save_list(R_e1_ROUSEG, \"R_e1_ROUSEG.json\",lists_dir)\n",
    "save_list(R_e2_ROUSEG, \"R_e2_ROUSEG.json\",lists_dir)\n",
    "save_list(M_dist_ROUSEG, \"M_dist_ROUSEG.json\", lists_dir)\n",
    "save_list(M_e0_ROUSEG, \"M_e0_ROUSEG.json\",lists_dir)\n",
    "save_list(M_e1_ROUSEG, \"M_e1_ROUSEG.json\",lists_dir)\n",
    "save_list(M_e2_ROUSEG, \"M_e2_ROUSEG.json\",lists_dir)\n",
    "save_list(L_dist_ROUSEG, \"L_dist_ROUSEG.json\", lists_dir)\n",
    "save_list(L_e0_ROUSEG, \"L_e0_ROUSEG.json\",lists_dir)\n",
    "save_list(L_e1_ROUSEG, \"L_e1_ROUSEG.json\",lists_dir)\n",
    "save_list(L_e2_ROUSEG, \"L_e2_ROUSEG.json\",lists_dir)\n",
    "\n",
    "save_list(R_dist_NETSEG, \"R_dist_NETSEG.json\", lists_dir)\n",
    "save_list(R_e0_NETSEG, \"R_e0_NETSEG.json\",lists_dir)\n",
    "save_list(R_e1_NETSEG, \"R_e1_NETSEG.json\",lists_dir)\n",
    "save_list(R_e2_NETSEG, \"R_e2_NETSEG.json\",lists_dir)\n",
    "save_list(M_dist_NETSEG, \"M_dist_NETSEG.json\", lists_dir)\n",
    "save_list(M_e0_NETSEG, \"M_e0_NETSEG.json\",lists_dir)\n",
    "save_list(M_e1_NETSEG, \"M_e1_NETSEG.json\",lists_dir)\n",
    "save_list(M_e2_NETSEG, \"M_e2_NETSEG.json\",lists_dir)\n",
    "save_list(L_dist_NETSEG, \"L_dist_NETSEG.json\", lists_dir)\n",
    "save_list(L_e0_NETSEG, \"L_e0_NETSEG.json\",lists_dir)\n",
    "save_list(L_e1_NETSEG, \"L_e1_NETSEG.json\",lists_dir)\n",
    "save_list(L_e2_NETSEG, \"L_e2_NETSEG.json\",lists_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
